"""
To figure out the impact of batch size in the inference time.
Expectation: Larger batch size make it possible for decrease inference time.
"""

hf_model_id="gpt2"
# hf_model_id="gpt2-medium"
# hf_model_id="gpt-large"
# hf_model_id="gpt-xl"